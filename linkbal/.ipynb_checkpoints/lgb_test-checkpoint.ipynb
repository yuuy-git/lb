{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from pathlib import Path\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# Setting paths, columns and dtypes. #\n",
    "######################################\n",
    "current_dir = Path('.')\n",
    "path_dir = current_dir / 'datasets'\n",
    "path_log = path_dir / 'log.tsv'\n",
    "path_events = path_dir / 'events.tsv'\n",
    "path_users = path_dir / 'users.tsv'\n",
    "\n",
    "\n",
    "\n",
    "log_cols = [\n",
    "    'user_id', 'event_id', 'time_stamp', 'action_type',\n",
    "    'num_of_people', 'payment_methond', 'total_price'\n",
    "]\n",
    "\n",
    "dtypes = {\n",
    "        'user_id'          : 'int',\n",
    "        'event_id'         : 'int',\n",
    "        'time_stamp'       : 'str',\n",
    "        'action_type'      : 'int',\n",
    "        'num_of_people'    : 'float',\n",
    "        'payment_methond'  : 'str',\n",
    "        'total_price'      : 'float',\n",
    "        'female_age_lower' : 'int',\n",
    "        'female_age_upper' : 'int',\n",
    "        'male_age_lower'   : 'int',\n",
    "        'male_age_upper'   : 'int',\n",
    "        'event_start_at'   : 'str',\n",
    "        'prefecture'       : 'str',\n",
    "        'first_published_at': 'str',\n",
    "        'female_price'     : 'int',\n",
    "        'male_price'       : 'int',\n",
    "        'interest'         : 'str',\n",
    "        'age'              : 'int',\n",
    "        'gender'           : 'str',\n",
    "        'createed_at'      : 'str'\n",
    "}\n",
    "\n",
    "\n",
    "prefecture_dict = {\n",
    "    '北海道'  :   0,\n",
    "    '青森県'  :   1,\n",
    "    '岩手県'  :   2,\n",
    "    '宮城県'  :   3,\n",
    "    '秋田県'  :   4,\n",
    "    '山形県'  :   5,\n",
    "    '福島県'  :   6,\n",
    "    '茨城県'  :   7,\n",
    "    '栃木県'  :   8,\n",
    "    '群馬県'  :   9,\n",
    "    '埼玉県'  :  10,\n",
    "    '千葉県'  :  11,\n",
    "    '東京都'  :  12,\n",
    "    '神奈川県':  13,\n",
    "    '新潟県'  :  14,\n",
    "    '富山県'  :  15,\n",
    "    '石川県'  :  16,\n",
    "    '福井県'  :  17,\n",
    "    '山梨県'  :  18,\n",
    "    '長野県'  :  19,\n",
    "    '岐阜県'  :  20,\n",
    "    '静岡県'  :  21,\n",
    "    '愛知県'  :  22,\n",
    "    '三重県'  :  23,\n",
    "    '滋賀県'  :  24,\n",
    "    '京都府'  :  25,\n",
    "    '大阪府'  :  26,\n",
    "    '兵庫県'  :  27,\n",
    "    '奈良県'  :  28,\n",
    "    '和歌山県':  29,\n",
    "    '鳥取県'  :  30,\n",
    "    '島根県'  :  31,\n",
    "    '岡山県'  :  32,\n",
    "    '広島県'  :  33,\n",
    "    '山口県'  :  34,\n",
    "    '徳島県'  :  35,\n",
    "    '香川県'  :  36,\n",
    "    '愛媛県'  :  37,\n",
    "    '高知県'  :  38,\n",
    "    '福岡県'  :  39,\n",
    "    '佐賀県'  :  40,\n",
    "    '長崎県'  :  41,\n",
    "    '熊本県'  :  42,\n",
    "    '大分県'  :  43,\n",
    "    '宮崎県'  :  44,\n",
    "    '鹿児島県':  45,\n",
    "    '沖縄県'  :  46,\n",
    "    'その他（海外等）': 47\n",
    "}\n",
    "\n",
    "\n",
    "gender_dict = {'男性':0, '女性':1}\n",
    "\n",
    "payment_method_dict = {\n",
    "    'クレカ'   :  0,\n",
    "    'コンビニ' :  1,\n",
    "    'eマネー'  :  2,\n",
    "    '銀振'     :  3\n",
    "}\n",
    "\n",
    "interest_dict = {\n",
    "    'アニメコン'                           :   0,\n",
    "    '謎解きコン'                           :   1,\n",
    "    'その他（スポーツコン）'                 :   2,\n",
    "    '料理合コン（料理コン）'                 :   3,\n",
    "    'スポーツコン'                         :   4,\n",
    "    'フットサルコン'                       :   5,\n",
    "    'ボルダリングコン'                      :   6,\n",
    "    'テニスコン'                           :   7,\n",
    "    '旅コン'                              :   8,\n",
    "    'サバコン'                            :   9,\n",
    "    '婚活バスツアー（お見合いバスツアー）'     :  10,\n",
    "    '釣りコン'                            :  11,\n",
    "    'その他'                              :  12\n",
    "}\n",
    "\n",
    "action_type_dict = {\n",
    "    1 : 0,\n",
    "    2 : 1,\n",
    "    3 : 2\n",
    "}\n",
    "\n",
    "dict_list = [prefecture_dict, gender_dict, payment_method_dict, interest_dict, action_type_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################################################\n",
    "# Reading tsv and merge them on 'user_id' and 'event_id'. #\n",
    "###########################################################\n",
    "\n",
    "print ('Loading and merging csv')\n",
    "\n",
    "df_log = pd.read_table(path_log, header=0, parse_dates=True, na_values='n/a')\n",
    "df_events = pd.read_table(path_events, header=0, parse_dates=True, na_values='n/a')\n",
    "df_users = pd.read_table(path_users, header=0, parse_dates=True, na_values='n/a')\n",
    "\n",
    "df = pd.merge(df_log, df_events, on='event_id', how='left')\n",
    "df = pd.merge(df, df_users, on='user_id', how='left', suffixes=('_event', '_user'))\n",
    "\n",
    "del df_log, df_events, df_users\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "# Replacing strings for int. #\n",
    "##############################\n",
    "'''\n",
    "def replace_int(df,column):\n",
    "    #count elements\n",
    "    contents = df[column]\n",
    "    element = []\n",
    "    for content in contents:\n",
    "        if not content in element:\n",
    "            element.append(content)\n",
    "    #element 2 dictionaly {element0: 0, element1:1, ..., elementk: k}\n",
    "    dict_element = dict(zip(element,range(0,len(element))))\n",
    "    #change element to int\n",
    "    df = df.replace(dict_element)\n",
    "    return df,dict_element\n",
    "\n",
    "print('Replacing str for int in the csv')\n",
    "\n",
    "dict_ref = {}\n",
    "df_rp = df\n",
    "col_list = ['prefecture_event', 'payment_method', 'gender', 'interest']\n",
    "\n",
    "for cols in col_list:\n",
    "    df_rp, dict_ref[cols] = replace_int(df_rp, cols)\n",
    "\n",
    "df_rp = df_rp.replace('その他（海外等）', 47)\n",
    "'''\n",
    "\n",
    "df_rp = df.copy()\n",
    "for dict in dict_list:\n",
    "    df_rp = df_rp.replace(dict)\n",
    "\n",
    "df_rp = df_rp.fillna(9999)\n",
    "\n",
    "del df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making datasets for train and test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######################################\n",
    "# Making datasets for train and test #\n",
    "######################################\n",
    "print('Making datasets for train and test')\n",
    "\n",
    "'''\n",
    ":param: x : all columns except user_id, event_id and y(action_type)\n",
    ":param: y : action_type column\n",
    "'''\n",
    "x_with_id = df_rp.drop(['action_type', 'time_stamp', 'event_start_at',\n",
    "                       'first_published_at', 'created_on'], axis=1).values\n",
    "y = df_rp.iloc[:, 3].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the datasets into the Training set and Test set\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##############################################################\n",
    "# Splitting the datasets into the Training set and Test set. #\n",
    "##############################################################\n",
    "print ('Splitting the datasets into the Training set and Test set')\n",
    "\n",
    "x_train_with_id, x_test_with_id, y_train, y_test = train_test_split(x_with_id, y, test_size = 0.25, random_state = 0)\n",
    "x_train = x_train_with_id[:, 2:]\n",
    "x_test = x_test_with_id[:, 2:]\n",
    "x_train_id = x_train_with_id[:, [0, 1]]\n",
    "x_test_id = x_test_with_id[:, [0, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "# Setting Dataset for LGB. #\n",
    "############################\n",
    "target = \"action_type\"\n",
    "predictors = ['num_of_people','payment_method', 'total_price',\n",
    "                'female_age_lower','female_age_upper',\n",
    "                'male_age_lower','male_age_upper',\n",
    "                'prefecture_event', 'female_price','male_price',\n",
    "                'interest', 'age', 'gender', 'prefecture_user']\n",
    "\n",
    "categorical_features = ['payment_method','prefecture_event',\n",
    "                        'interest', 'gender', 'prefecture_user']\n",
    "\n",
    "lgb_train = lgb.Dataset(x_train, y_train,\n",
    "                        feature_name=predictors,\n",
    "                        categorical_feature=categorical_features)\n",
    "\n",
    "lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################\n",
    "# Setting parameters. #\n",
    "#######################\n",
    "\n",
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'subsample_for_bin': 200000,  # Number of samples for constructing bin\n",
    "    'min_split_gain': 0,  # lambda_l1, lambda_l2 and min_gain_to_split to regularization\n",
    "    'reg_alpha': 0,  # L1 regularization term on weights\n",
    "    'reg_lambda': 0,  # L2 regularization term on weights\n",
    "    'nthread': 4,  # Number of threads for LightGBM\n",
    "    'verbose': 0,\n",
    "    'metric':'auc',\n",
    "\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 15,  # 2^max_depth - 1\n",
    "    'max_depth': 4,  # -1 means no limit\n",
    "    'min_child_samples': 100,  # Minimum number of data need in a child(min_data_in_leaf)\n",
    "    'max_bin': 100,  # Number of bucketed bin for feature values\n",
    "    'subsample': 0.7,  # Subsample ratio of the training instance.\n",
    "    'subsample_freq': 1,  # frequence of subsample, <=0 means no enable\n",
    "    'colsample_bytree': 0.9,  # Subsample ratio of columns when constructing each tree.\n",
    "    'min_child_weight': 0,  # Minimum sum of instance weight(hessian) needed in a child(leaf)\n",
    "    'scale_pos_weight':99\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/anaconda3/lib/python3.5/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/tk/anaconda3/lib/python3.5/site-packages/lightgbm/basic.py:1038: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['gender', 'interest', 'payment_method', 'prefecture_event', 'prefecture_user']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/tk/anaconda3/lib/python3.5/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overrided.\n",
      "  warnings.warn('categorical_feature in param dict is overrided.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.237973\n",
      "Training until validation scores don't improve for 30 rounds.\n",
      "[2]\tvalid_0's auc: 0.221898\n",
      "[3]\tvalid_0's auc: 0.222497\n",
      "[4]\tvalid_0's auc: 0.220262\n",
      "[5]\tvalid_0's auc: 0.219334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's auc: 0.237973\n",
      "Training is done.\n",
      "Start predicting...\n",
      "Prediction is done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###########################\n",
    "# Training and Predicting #\n",
    "###########################\n",
    "\n",
    "print('Start training...')\n",
    "\n",
    "evals_result = {}\n",
    "num_boost_round = 5\n",
    "early_stopping_rounds = 30\n",
    "\n",
    "booster = lgb.train(\n",
    "     lgb_params,\n",
    "     lgb_train,\n",
    "     valid_sets=lgb_eval, #  List of data to be evaluated during training.\n",
    "     evals_result=evals_result,\n",
    "     num_boost_round=num_boost_round,\n",
    "     early_stopping_rounds=early_stopping_rounds,\n",
    "#     verbose_eval=1  # This tells us how it is going on in each iteretion.\n",
    ")\n",
    "\n",
    "print('Training is done.')\n",
    "\n",
    "\n",
    "print('Start predicting...')\n",
    "\n",
    "predictions=booster.predict(x_test, num_iteration=booster.best_iteration)\n",
    "\n",
    "print('Prediction is done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: ['num_of_people', 'payment_method', 'total_price', 'female_age_lower', 'female_age_upper', 'male_age_lower', 'male_age_upper', 'prefecture_event', 'female_price', 'male_price', 'interest', 'age', 'gender', 'prefecture_user']\n",
      "Calculate feature importances...\n",
      "Feature importances: [3, 2, 4, 0, 2, 1, 0, 3, 1, 0, 0, 2, 0, 5]\n",
      "Exporting to csv\n",
      "Saving the model...\n",
      "Above lightgbm_model.txt file is saved at your local file system, mostly where jupyter notebook started\n",
      "All done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###################################\n",
    "# Showing and saving the results. #\n",
    "###################################\n",
    "\n",
    "print('Feature names:', booster.feature_name())\n",
    "print('Calculate feature importances...')\n",
    "print('Feature importances:', list(booster.feature_importance()))\n",
    "\n",
    "\n",
    "print('Exporting to csv')\n",
    "results = pd.DataFrame()\n",
    "\n",
    "results_list = ['user_id', 'event_id']\n",
    "for i, col in enumerate(results_list):\n",
    "    results[col] = x_test_id[:, i]\n",
    "    \n",
    "prediction_list = ['click', 'favorite', 'entry']\n",
    "for i, col in enumerate(prediction_list):\n",
    "    results[col]  = predictions[:, i]\n",
    "\n",
    "results.to_csv('lgb_result.csv', float_format='%.8f', index=False)\n",
    "\n",
    "print('Saving the model...')\n",
    "# save model to file\n",
    "booster.save_model('lightgbm_model.txt')\n",
    "print('Above lightgbm_model.txt file is saved at your local file system, mostly where jupyter notebook started')\n",
    "\n",
    "print(\"All done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
